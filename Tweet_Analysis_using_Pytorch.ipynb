{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweet Analysis using Pytorch",
      "version": "0.3.2",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayaliKutwal/udacity-showcase-challenge/blob/master/Tweet_Analysis_using_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6d0GiP8m4iU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKX_HtSmnGjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Helper functions\n",
        "import pickle\n",
        "\n",
        "def convert_to_pickle(item, directory):\n",
        "    pickle.dump(item, open(directory,\"wb\"))\n",
        "\n",
        "\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "679bR-2qnKX-",
        "colab_type": "code",
        "outputId": "33af4e9e-dc83-4142-9fa9-26427eba030b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "### read data from your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n77fvrCQni3u",
        "colab_type": "code",
        "outputId": "1afc80cb-59a4-4f2c-eb1c-3d69bf906134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "# load data\n",
        "data = load_from_pickle(directory=\"/gdrive/My Drive/Colab Notebooks/000 Tweet analysis/merged_training.pkl\")\n",
        "data.emotions.value_counts().plot.bar()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5529de49e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEbCAYAAAAmmNiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERtf1/4EfnAP+MudQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHpcbTvesQaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtjqPB0VsF-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# retain only text that contain less that 70 tokens to avoid too much padding\n",
        "data[\"token_size\"] = data[\"text\"].apply(lambda x: len(x.split(' ')))\n",
        "data = data.loc[data['token_size'] < 70].copy()\n",
        "\n",
        "# sampling\n",
        "data = data.sample(n=50000);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXxq0Tq6sa8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for the dataset\n",
        "class ConstructVocab():\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        for s in self.sentences:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(s.split(' '))\n",
        "            \n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        \n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        \n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61ZGU3mRsdFo",
        "colab_type": "code",
        "outputId": "03e7c5c8-edc4-49ce-9b39-c21a18cb013f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# construct vocab and indexing\n",
        "inputs = ConstructVocab(data[\"text\"].values.tolist())\n",
        "\n",
        "# examples of what is in the vocab\n",
        "inputs.vocab[0:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'aa',\n",
              " 'aaaaah',\n",
              " 'aaaaall',\n",
              " 'aaaah',\n",
              " 'aaaand',\n",
              " 'aaahs',\n",
              " 'aaargh',\n",
              " 'aabsolutely',\n",
              " 'aadmi']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmytPKv-smvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize to tensor\n",
        "input_tensor = [[inputs.word2idx[s] for s in es.split(' ')]  for es in data[\"text\"].values.tolist()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx1XxxoHswXx",
        "colab_type": "code",
        "outputId": "1c367637-c9a8-4491-f557-e443c52a4823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# examples of what is in the input tensors\n",
        "input_tensor[0:1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[11594,\n",
              "  772,\n",
              "  8772,\n",
              "  15662,\n",
              "  13713,\n",
              "  1031,\n",
              "  876,\n",
              "  15662,\n",
              "  15511,\n",
              "  7830,\n",
              "  26857,\n",
              "  7371,\n",
              "  5860,\n",
              "  12971,\n",
              "  23820,\n",
              "  24198,\n",
              "  16204,\n",
              "  9692,\n",
              "  7224]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qXKO2nHs3iQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra4wF13Es9SU",
        "colab_type": "code",
        "outputId": "056824f4-f903-4720-c214-c418e69d415a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the max_length of input tensor\n",
        "max_length_inp = max_length(input_tensor)\n",
        "print(max_length_inp)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZkD_distCW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len: padded[:] = x[:max_len]\n",
        "    else: padded[:len(x)] = x\n",
        "    return padded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qBbVZUFtLBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inplace padding\n",
        "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns_7ucv0tRDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#input_tensor[0:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EdhFToWtYXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### convert targets to one-hot encoding vectors\n",
        "emotions = list(set(data.emotions.unique()))\n",
        "num_emotions = len(emotions)\n",
        "# binarizer\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(emos) & set(emotions) for emos in data[['emotions']].values]\n",
        "bin_emotions = mlb.fit_transform(data_labels)\n",
        "target_tensor = np.array(bin_emotions.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf5wBFFctfQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#target_tensor[0:2] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIafsiLJtlq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data[0:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRHtFac1ttIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_emotion = lambda t: np.argmax(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl9V5LL4ty9J",
        "colab_type": "code",
        "outputId": "b504bf0b-3011-4731-f38d-2210bccfdaed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_emotion(target_tensor[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0abz3uyTt2eD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emotion_dict = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DliGkjtlt8EZ",
        "colab_type": "code",
        "outputId": "5a43bc0d-81f9-4e9c-e8cf-35a8e9c0d362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "emotion_dict[get_emotion(target_tensor[0])]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fear'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7N2R6xjIuB7r",
        "colab_type": "code",
        "outputId": "46d5b7e3-7099-4c33-8761-993cb841d719",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val), len(input_tensor_test), len(target_tensor_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 40000, 5000, 5000, 5000, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ7l6TIAuGuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BUFFER_SIZE = len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = len(input_tensor_val)\n",
        "TEST_BUFFER_SIZE = len(input_tensor_test)\n",
        "BATCH_SIZE = 64\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inputs.word2idx)\n",
        "target_size = num_emotions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58uVF-xOuf63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdnqnwY-unch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the data to tensors and pass to the Dataloader \n",
        "# to create an batch iterator\n",
        "\n",
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x, y, x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzW79zvqusRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "test_dataset = MyData(input_tensor_test, target_tensor_test)\n",
        "\n",
        "train_dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "val_dataset = DataLoader(val_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "test_dataset = DataLoader(test_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkMT78AGuv7-",
        "colab_type": "code",
        "outputId": "240b6a22-3279-4ab5-e4fb-df73ce0aa8ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "val_dataset.batch_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7rAOrOcu1sK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class EmoGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n",
        "        super(EmoGRU, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.hidden_units = hidden_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        # layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.hidden_units)\n",
        "        self.fc = nn.Linear(self.hidden_units, self.output_size)\n",
        "    \n",
        "    def initialize_hidden_state(self, device):\n",
        "        return torch.zeros((1, self.batch_sz, self.hidden_units)).to(device)\n",
        "    \n",
        "    def forward(self, x, lens, device):\n",
        "        x = self.embedding(x)\n",
        "        self.hidden = self.initialize_hidden_state(device)\n",
        "        output, self.hidden = self.gru(x, self.hidden) # max_len X batch_size X hidden_units\n",
        "        out = output[-1, :, :] \n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out, self.hidden  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss9e-bevu6CP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_batch(X, y, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSfAusZwv4gZ",
        "colab_type": "code",
        "outputId": "eeb24a4b-dc96-4844-eb19-5b5121be3620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(train_dataset)\n",
        "x, y, x_len = next(it)\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack sequence\n",
        "xs, ys, lens = sort_batch(x, y, x_len)\n",
        "\n",
        "print(\"Input size: \", xs.size())\n",
        "\n",
        "output, _ = model(xs.to(device), lens, device)\n",
        "print(output.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input size:  torch.Size([69, 64])\n",
            "torch.Size([64, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8vt3-qDv8Hl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Enabling cuda\n",
        "use_cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "### loss criterion and optimizer for training\n",
        "criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "def loss_function(y, prediction):\n",
        "    \"\"\" CrossEntropyLoss expects outputs and class indices as target \"\"\"\n",
        "    # convert from one-hot encoding to class indices\n",
        "    target = torch.max(y, 1)[1]\n",
        "    loss = criterion(prediction, target) \n",
        "    return loss   #TODO: refer the parameter of these functions as the same\n",
        "    \n",
        "def accuracy(target, logit):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    target = torch.max(target, 1)[1] # convert from one-hot encoding to class indices\n",
        "    corrects = (torch.max(logit, 1)[1].data == target).sum()\n",
        "    accuracy = 100.0 * corrects / len(logit)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEuUEFbywCs7",
        "colab_type": "code",
        "outputId": "172916bb-1049-432e-9cea-f083550d3058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "EPOCHS = 1\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    ### Initialize hidden state\n",
        "    # TODO: do initialization here.\n",
        "    total_loss = 0\n",
        "    train_accuracy, val_accuracy = 0, 0\n",
        "    \n",
        "    ### Training\n",
        "    for (batch, (inp, targ, lens)) in enumerate(train_dataset):\n",
        "        loss = 0\n",
        "        predictions, _ = model(inp.permute(1 ,0).to(device), lens, device) # TODO:don't need _   \n",
        "              \n",
        "        loss += loss_function(targ.to(device), predictions)\n",
        "        batch_loss = (loss / int(targ.shape[1]))        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        train_accuracy += batch_accuracy\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Val. Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.cpu().detach().numpy()))\n",
        "            \n",
        "    ### Validating\n",
        "    for (batch, (inp, targ, lens)) in enumerate(val_dataset):        \n",
        "        predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        val_accuracy += batch_accuracy\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f} -- Train Acc. {:.4f} -- Val Acc. {:.4f}'.format(epoch + 1, \n",
        "                                                             total_loss / TRAIN_N_BATCH, \n",
        "                                                             train_accuracy / TRAIN_N_BATCH,\n",
        "                                                             val_accuracy / VAL_N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Val. Loss 0.3067\n",
            "Epoch 1 Batch 100 Val. Loss 0.2927\n",
            "Epoch 1 Batch 200 Val. Loss 0.2576\n",
            "Epoch 1 Batch 300 Val. Loss 0.1018\n",
            "Epoch 1 Batch 400 Val. Loss 0.0517\n",
            "Epoch 1 Batch 500 Val. Loss 0.0527\n",
            "Epoch 1 Batch 600 Val. Loss 0.0303\n",
            "Epoch 1 Loss 0.1432 -- Train Acc. 66.0000 -- Val Acc. 90.0000\n",
            "Time taken for 1 epoch 1218.0074489116669 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ARItYfmwHdl",
        "colab_type": "code",
        "outputId": "c48f9eb7-2e53-4153-8474-7c0dcb4d4185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "model.parameters"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of EmoGRU(\n",
              "  (embedding): Embedding(27350, 256)\n",
              "  (dropout): Dropout(p=0.5)\n",
              "  (gru): GRU(256, 1024)\n",
              "  (fc): Linear(in_features=1024, out_features=6, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1MxHg5a-XHg",
        "colab_type": "code",
        "outputId": "a7b38472-b7a1-4e8a-d1f5-967a483582d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "test_accuracy = 0\n",
        "all_predictions = []\n",
        "x_raw = []\n",
        "y_raw = []\n",
        "\n",
        "#device = \"cuda\" # we don't need GPU to do testing\n",
        "#model.to(\"cuda\")\n",
        "use_cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "for (batch, (inp, targ, lens)) in enumerate(test_dataset):          \n",
        "    predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n",
        "    batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "    test_accuracy += batch_accuracy\n",
        "    \n",
        "    x_raw = x_raw + [x for x in inp]\n",
        "    y_raw = y_raw + [y for y in targ]\n",
        "    \n",
        "    all_predictions.append(predictions)\n",
        "    \n",
        "print(\"Test Accuracy: \", test_accuracy.cpu().detach().numpy() / TEST_N_BATCH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2241ca3dfca7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#device = \"cuda\" # we don't need GPU to do testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#model.to(\"cuda\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4QVz2RWzaIJ",
        "colab_type": "code",
        "outputId": "118c94ce-8ff0-460c-e120-72feffbdf114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "source": [
        "#Confusion Matrix\n",
        "!pip install helpers\n",
        "\n",
        "!wget https://github.com/ematvey/tensorflow-seq2seq-tutorials/blob/master/helpers.py\n",
        "\n",
        "import helpers.evaluate as ev\n",
        "evaluator = ev.Evaluate()\n",
        "import pandas as pd\n",
        "\n",
        "final_predictions = []\n",
        "\n",
        "for p in all_predictions:\n",
        "    for sub_p in p:\n",
        "        final_predictions.append(sub_p.detach().numpy())\n",
        "        \n",
        "predictions = [np.argmax(p).item() for p in final_predictions]\n",
        "targets = [np.argmax(t).item() for t in y_raw]\n",
        "correct_predictions = float(np.sum(predictions == targets))\n",
        "\n",
        "# predictions\n",
        "predictions_human_readable = ((x_raw, predictions))\n",
        "# actual targets\n",
        "target_human_readable = ((x_raw,  targets))\n",
        "\n",
        "emotion_dict = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}\n",
        "\n",
        "# convert results into dataframe\n",
        "model_test_result = pd.DataFrame(predictions_human_readable[1],columns=[\"emotion\"])\n",
        "test = pd.DataFrame(target_human_readable[1], columns=[\"emotion\"])\n",
        "\n",
        "model_test_result.emotion = model_test_result.emotion.map(lambda x: emotion_dict[int(float(x))])\n",
        "test.emotion = test.emotion.map(lambda x: emotion_dict[int(x)])\n",
        "\n",
        "evaluator.evaluate_class(model_test_result.emotion, test.emotion );"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: helpers in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "--2019-08-17 14:12:42--  https://github.com/ematvey/tensorflow-seq2seq-tutorials/blob/master/helpers.py\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘helpers.py.1’\n",
            "\n",
            "helpers.py.1            [  <=>               ]  81.05K   227KB/s    in 0.4s    \n",
            "\n",
            "2019-08-17 14:12:43 (227 KB/s) - ‘helpers.py.1’ saved [82993]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-ee1230e6210d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget https://github.com/ematvey/tensorflow-seq2seq-tutorials/blob/master/helpers.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helpers.evaluate'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF0RH-GU-d__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}